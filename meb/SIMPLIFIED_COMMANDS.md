# meb Simplified Commands

El sistema meb ha sido simplificado para eliminar la capa de adapters, manteniendo solo la funcionalidad esencial de SLERP para fusi√≥n multimodal.

## Arquitectura Simplificada

```
Encoder (embeddings directos) ‚Üí SLERP Fusion (Œ±,Œ≤) ‚Üí FAISS Search ‚Üí NDCG
```

**Lo que se elimin√≥:**
- Capa de adapters (PCA, normalizaci√≥n, rotaci√≥n, etc.)
- Transformaciones adicionales de embeddings

**Lo que se mantiene:**
- Fusi√≥n multimodal SLERP entre embeddings de texto e imagen
- Par√°metros Œ± (alpha) y Œ≤ (beta) para controlar la fusi√≥n
- Motor FAISS con b√∫squeda eficiente
- Evaluaci√≥n NDCG con matching por ID

## Comandos Bash Simplificados

### 1. Evaluaci√≥n B√°sica con Embeddings Precomputados

```bash
# Evaluaci√≥n est√°ndar con dataset provider
python meb/run_evaluation.py --encoder precomputed --dataset provider

# Evaluaci√≥n con dataset espec√≠fico
python meb/run_evaluation.py --encoder precomputed --dataset fashion_ecommerce
python meb/run_evaluation.py --encoder precomputed --dataset electronics
```

### 2. Evaluaci√≥n con Diferentes Encoders

```bash
# Encoder precomputado (por defecto)
python meb/run_evaluation.py --encoder precomputed --dataset provider

# Encoder mock para testing
python meb/run_evaluation.py --encoder mock --dataset provider

# Encoder HuggingFace (si est√° disponible)
python meb/run_evaluation.py --encoder sentence-transformers/all-MiniLM-L6-v2 --dataset provider

# Google API Encoder (requiere configuraci√≥n de Google Cloud)
python meb/run_evaluation.py --encoder google_api --dataset provider
```

### 2.1. Google API Encoder

El nuevo **Google API Encoder** utiliza las APIs de Google Cloud Vertex AI para generar embeddings de alta calidad tanto para texto como para im√°genes.

#### Configuraci√≥n Requerida

```bash
# 1. Instalar dependencias
pip install -r meb/requirements_google_api.txt

# 2. Configurar autenticaci√≥n de Google Cloud
export GOOGLE_CLOUD_PROJECT=tu-project-id
gcloud auth application-default login

# 3. Habilitar APIs necesarias
gcloud services enable aiplatform.googleapis.com
```

#### Uso B√°sico

```bash
# Configuraci√≥n simple (usa variable de entorno GOOGLE_CLOUD_PROJECT)
export GOOGLE_CLOUD_PROJECT=tu-project-id
python meb/run_evaluation.py --encoder google_api --dataset provider

# Configuraci√≥n avanzada con archivo JSON
python meb/run_evaluation.py --config google_api_config.json
```

#### Configuraci√≥n Avanzada

Crear `google_api_config.json`:

```json
{
  "encoder": {
    "type": "google_api",
    "project_id": "tu-project-id",
    "location": "us-central1",
    "text_model": "text-embedding-004",
    "image_model": "multimodalembedding@001",
    "rate_limit_requests_per_minute": 60,
    "batch_size": 5,
    "max_retries": 3,
    "name": "google_api_custom"
  },
  "datasets": "provider"
}
```

#### Modelos Disponibles

- **Texto**: `text-embedding-004`, `text-multilingual-embedding-002`
- **Im√°genes**: `multimodalembedding@001`
- **Dimensiones**: 768 (texto), 1408 (imagen)

#### Caracter√≠sticas

- ‚úÖ **Rate limiting** autom√°tico para respetar l√≠mites de API
- ‚úÖ **Batch processing** para eficiencia
- ‚úÖ **Retry logic** con backoff exponencial
- ‚úÖ **Caching** integrado para evitar llamadas duplicadas
- ‚úÖ **Async processing** para mejor rendimiento
- ‚úÖ **Error handling** robusto

#### Ejemplo de Uso Program√°tico

```python
from meb.models.google_api_encoder import GoogleAPIEncoder

# Configuraci√≥n b√°sica
encoder = GoogleAPIEncoder(project_id="tu-project-id")

# Generar embeddings
text_embeddings = encoder.encode_text(["Texto de ejemplo"])
image_embeddings = encoder.encode_image(["imagen.jpg"])

# Ver informaci√≥n del modelo
print(encoder.get_model_info())
```

### 3. Control de Fusi√≥n Multimodal

Los par√°metros Œ± y Œ≤ se eval√∫an autom√°ticamente en el rango [0.0, 0.25, 0.5, 0.75, 1.0]:

- **Œ±=0, Œ≤=0**: Solo texto
- **Œ±=1, Œ≤=1**: Solo imagen  
- **Œ±=0.5, Œ≤=0.5**: Fusi√≥n balanceada

```bash
# Evaluaci√≥n completa con todos los par√°metros Œ±,Œ≤
python meb/run_evaluation.py --encoder precomputed --dataset provider

# Los resultados mostrar√°n el mejor Œ±,Œ≤ para cada dataset
```

### 4. Opciones Adicionales

```bash
# Usar GPU para FAISS (si est√° disponible)
python meb/run_evaluation.py --encoder precomputed --dataset provider --use-gpu

# Especificar directorio de salida
python meb/run_evaluation.py --encoder precomputed --dataset provider --output-dir my_results

# Usar archivo de configuraci√≥n personalizado
python meb/run_evaluation.py --config my_config.json
```

### 5. Evaluaci√≥n de Todos los Datasets

```bash
# Evaluar todos los datasets disponibles
python meb/run_evaluation.py --encoder precomputed

# Esto evaluar√° autom√°ticamente: provider, fashion_ecommerce, electronics
```

## Resultados

Los resultados se guardan en:
- **JSON**: `results/advanced_evaluation_YYYYMMDD_HHMMSS.json`
- **Resumen**: `results/advanced_summary_YYYYMMDD_HHMMSS.txt`

### Ejemplo de Salida

```
üéØ ADVANCED EVALUATION COMPLETE!
==================================================
üìÅ Results saved to: results/advanced_evaluation_20250911_131452.json
üìÑ Summary saved to: results/advanced_summary_20250911_131452.txt

üìä Key Findings:
   ‚Ä¢ Encoder: precomputed
   ‚Ä¢ Datasets evaluated: 1
   ‚Ä¢ Average NDCG@5: 1.0000 ¬± 0.0000
   ‚Ä¢ Best parameters: Œ±=0.0, Œ≤=0.0
```

## Configuraci√≥n Personalizada

Crear un archivo `config.json`:

```json
{
  "encoder": "precomputed",
  "datasets": "provider",
  "alpha_values": [0.0, 0.5, 1.0],
  "beta_values": [0.0, 0.5, 1.0],
  "k_values": [1, 5, 10],
  "index_type": "flat",
  "engine": {
    "use_gpu": false,
    "cache_dir": "cache"
  }
}
```

Luego ejecutar:

```bash
python meb/run_evaluation.py --config config.json
```

## Ventajas del Sistema Simplificado

1. **M√°s directo**: Sin capas intermedias de transformaci√≥n
2. **M√°s r√°pido**: Menos procesamiento de embeddings
3. **M√°s claro**: Flujo de evaluaci√≥n m√°s f√°cil de entender
4. **Mantiene SLERP**: Conserva la funcionalidad multimodal esencial
5. **Compatible**: Funciona con todos los datasets existentes

## Casos de Uso T√≠picos

```bash
# Evaluaci√≥n r√°pida de un dataset
python meb/run_evaluation.py --encoder precomputed --dataset provider

# Evaluaci√≥n completa de todos los datasets
python meb/run_evaluation.py --encoder precomputed

# Evaluaci√≥n con GPU para datasets grandes
python meb/run_evaluation.py --encoder precomputed --use-gpu

# Evaluaci√≥n con encoder personalizado
python meb/run_evaluation.py --encoder my_custom_encoder --dataset provider

# üÜï BENCHMARKING COMPLETO: Todos los encoders x todos los datasets
python meb/run_evaluation.py --benchmark-all
```

## üöÄ Nuevo: Benchmarking Completo

### Comando `--benchmark-all`

El nuevo flag `--benchmark-all` ejecuta una evaluaci√≥n comprehensiva de **todos los encoders disponibles** en **todos los datasets disponibles**, generando un an√°lisis comparativo completo.

#### Uso B√°sico

```bash
# Benchmarking autom√°tico (detecta encoders disponibles)
python meb/run_evaluation.py --benchmark-all

# Con GPU para mayor velocidad
python meb/run_evaluation.py --benchmark-all --use-gpu

# Especificar directorio de salida
python meb/run_evaluation.py --benchmark-all --output-dir benchmark_results
```

#### Detecci√≥n Autom√°tica de Encoders

El sistema detecta autom√°ticamente qu√© encoders est√°n disponibles:

- ‚úÖ **`precomputed`**: Siempre disponible (baseline)
- ‚úÖ **`google_adapter`**: Si existe `utils/models/adapter.onnx`
- ‚úÖ **`google_api`**: Si `GOOGLE_CLOUD_PROJECT` est√° configurado
- ‚ùå **`mock`**: Excluido del benchmarking (solo desarrollo)

#### Salida del Benchmarking

```
üîç Benchmark mode: Detecting available encoders...
‚úÖ precomputed: Available (baseline)
‚úÖ google_adapter: Available (ONNX model found)
‚ùå google_api: Not available (GOOGLE_CLOUD_PROJECT not set)

üöÄ Starting comprehensive benchmark
üìä Encoders to test: ['precomputed', 'google_adapter']
üìÅ Datasets to evaluate: ['provider', 'fashion_ecommerce', 'electronics']

üîÑ Testing encoder: precomputed
  üìä Evaluating dataset: provider
    ‚úÖ NDCG@5: 1.0000 (Œ±=0.0, Œ≤=0.0)
  üìä Evaluating dataset: fashion_ecommerce
    ‚úÖ NDCG@5: 0.8500 (Œ±=0.5, Œ≤=0.5)
  üìä Evaluating dataset: electronics
    ‚úÖ NDCG@5: 0.9200 (Œ±=0.25, Œ≤=0.75)

üîÑ Testing encoder: google_adapter
  üìä Evaluating dataset: provider
    ‚úÖ NDCG@5: 0.9800 (Œ±=0.0, Œ≤=0.25)
  üìä Evaluating dataset: fashion_ecommerce
    ‚úÖ NDCG@5: 0.8700 (Œ±=0.5, Œ≤=0.5)
  üìä Evaluating dataset: electronics
    ‚úÖ NDCG@5: 0.9100 (Œ±=0.25, Œ≤=0.5)
```

#### Resultados Generados

El benchmarking genera dos archivos:

1. **`benchmark_all_YYYYMMDD_HHMMSS.json`**: Resultados completos en JSON
2. **`benchmark_summary_YYYYMMDD_HHMMSS.txt`**: Resumen legible

#### Ejemplo de Resumen

```
meb Comprehensive Benchmark Results

üèÜ ENCODER RANKINGS:
1. precomputed: 0.9233 ¬± 0.0764 (3/3 datasets)
2. google_adapter: 0.9200 ¬± 0.0458 (3/3 datasets)

üìä DATASET DIFFICULTY:
electronics: 0.9150 ¬± 0.0071 (2/2 encoders)
provider: 0.9900 ¬± 0.0141 (2/2 encoders)
fashion_ecommerce: 0.8600 ¬± 0.0141 (2/2 encoders)

üìã DETAILED RESULTS MATRIX:
Encoder         | Provider | Fashion  | Electronics | Average
----------------------------------------------------------------
precomputed     | 1.0000   | 0.8500   | 0.9200      | 0.9233
google_adapter  | 0.9800   | 0.8700   | 0.9100      | 0.9200
```

#### An√°lisis Autom√°tico

El sistema calcula autom√°ticamente:

- **Ranking de encoders** por NDCG@5 promedio
- **Dificultad de datasets** (menor NDCG@5 = m√°s dif√≠cil)
- **Mejor encoder overall**
- **Dataset m√°s dif√≠cil**
- **Matriz de resultados completa**
- **Estad√≠sticas de √©xito/fallo**

#### Ventajas del Benchmarking

1. **Comparaci√≥n objetiva** entre todos los encoders disponibles
2. **Detecci√≥n autom√°tica** de configuraciones disponibles
3. **An√°lisis estad√≠stico** completo con medias y desviaciones
4. **Identificaci√≥n de fortalezas** por dataset y encoder
5. **Resultados reproducibles** con timestamps y configuraciones guardadas

#### Tiempo de Ejecuci√≥n

- **precomputed**: ~30 segundos por dataset (usa embeddings precalculados)
- **google_adapter**: ~2-5 minutos por dataset (transformaciones ONNX)
- **google_api**: ~5-15 minutos por dataset (llamadas API + rate limiting)

**Total estimado**: 15-60 minutos dependiendo de encoders disponibles y datasets.

## üÜï Nueva Funcionalidad: Embeddings Precomputados

El `Adapter` ahora soporta trabajar directamente con embeddings precomputados, adem√°s del m√©todo tradicional desde textos/im√°genes.

### M√©todos Disponibles

#### 1. M√©todo Tradicional (desde textos/im√°genes)
```python
from models.adapter import Adapter

finetuned = Adapter(base_encoder="mock")
text_embeddings = finetuned.encode_text(["texto 1", "texto 2"])
image_embeddings = finetuned.encode_image(["img1.jpg", "img2.jpg"])
```

#### 2. Nuevo M√©todo (desde embeddings precomputados)
```python
from models.finetuning_adapter import Adapter
from models.encoders import MockEncoder

# Obtener embeddings base de cualquier encoder
base_encoder = MockEncoder()
base_text_emb = base_encoder.encode_text(["texto 1", "texto 2"])
base_image_emb = base_encoder.encode_image(["img1.jpg", "img2.jpg"])

# Aplicar transformaciones de fine-tuning
finetuned = Adapter()
transformed_text = finetuned.transform_text_embeddings(base_text_emb)
transformed_image = finetuned.transform_image_embeddings(base_image_emb)
```

#### 3. Transformaci√≥n a Nivel de Dataset (con cach√©)
```python
# Transformar dataset completo con soporte de cach√©
text_emb, image_emb = finetuned.transform_embeddings_dataset(
    base_text_emb, base_image_emb, 
    dataset_name="mi_dataset", 
    data_type="catalog",
    use_cache=True
)
```

### Ventajas de los Embeddings Precomputados

1. **Eficiencia**: No necesitas recomputar embeddings base si ya los tienes
2. **Flexibilidad**: Puedes usar cualquier encoder base y aplicar fine-tuning despu√©s
3. **Compatibilidad**: Mantiene compatibilidad total con el m√©todo tradicional
4. **Cach√©**: Soporte completo de cach√© para transformaciones

### Casos de Uso

```python
# Caso 1: Tienes embeddings de un modelo costoso y quieres aplicar fine-tuning
expensive_embeddings = load_expensive_model_embeddings()
finetuned_embeddings = finetuned_encoder.transform_text_embeddings(expensive_embeddings)

# Caso 2: Experimentar con diferentes transformaciones sobre los mismos embeddings base
base_embeddings = base_encoder.encode_text(texts)
linear_transform = Adapter(transformation_type="linear")
mlp_transform = Adapter(transformation_type="mlp")

result1 = linear_transform.transform_text_embeddings(base_embeddings)
result2 = mlp_transform.transform_text_embeddings(base_embeddings)

# Caso 3: Pipeline de procesamiento por lotes
for batch in large_dataset:
    base_emb = batch_encoder.encode_text(batch.texts)
    transformed_emb = finetuned.transform_text_embeddings(base_emb)
    save_to_database(transformed_emb)
```

### Pruebas

Para probar la nueva funcionalidad:

```bash
# Ejecutar script de pruebas
cd meb && python test_precomputed_embeddings.py
```

Este script verifica que:
- Los m√©todos tradicionales y nuevos dan resultados consistentes
- El cach√© funciona correctamente
- Las transformaciones se aplican correctamente
